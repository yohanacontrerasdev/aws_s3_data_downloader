{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Get the data\n",
    "\n",
    "**Download the data by executing the code below:**\n",
    "\n",
    "`Notes:`\n",
    "* This script will download all PDF files from an AWS S3 bucket, maintaining the directory structure, and store them in a DataFrame.\n",
    "* Ensure you have the necessary AWS credentials and configurations set in a .env file.\n",
    "* The script uses boto3 to interact with S3, pandas to handle the data, and re for string manipulation.\n",
    "* The script first downloads all PDF files, then filters these files to obtain those with the most recent and oldest years per company.\n",
    "* Finally, it extracts the content of the filtered PDFs using the LlamaParse library.\n",
    "* The extracted content is stored in a new DataFrame, which includes the PDF file names and their corresponding text content.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T22:20:16.609619Z",
     "start_time": "2024-07-24T22:20:14.492759Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/oem/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importing the necessary libraries\n",
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from src.plots import(\n",
    "  analyze_text,\n",
    "  analyze_sentiment,\n",
    "  generate_word_cloud,\n",
    "  plot_common_words,\n",
    "  display_ngrams_with_plot_side_by_side\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T22:20:34.151722Z",
     "start_time": "2024-07-24T22:20:16.611719Z"
    }
   },
   "outputs": [],
   "source": [
    "from src import data_utils\n",
    "\n",
    "# From the notebook, set the variable to choose the method and call the function\n",
    "USE_LLAMAPARSE = False  # or False to use fitz\n",
    "LLAMAPARSE_API_KEY = os.getenv(\"LLAMAPARSE_API_KEY\")\n",
    "\n",
    "# Call the function to download the PDFs\n",
    "filtered_pdfs_df = data_utils.download_pdfs_and_convert_to_text(use_llamaparse=USE_LLAMAPARSE, llamaparse_api_key=LLAMAPARSE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>content</th>\n",
       "      <th>year</th>\n",
       "      <th>base_name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NASDAQ_FLWS_2019.pdf</td>\n",
       "      <td>b'%PDF-1.6\\r%\\xe2\\xe3\\xcf\\xd3\\r\\n1183 0 obj\\r&lt;...</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NASDAQ_FLWS</td>\n",
       "      <td>D R I V I N G  G R O W T H ,  \\nB U I L D I N ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NASDAQ_FLWS_2022.pdf</td>\n",
       "      <td>b'%PDF-1.7\\r%\\xe2\\xe3\\xcf\\xd3\\r\\n743 0 obj\\r&lt;&lt;...</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>NASDAQ_FLWS</td>\n",
       "      <td>1-800-FLOWERS.COM, INC. \\nLETTER TO SHAREHOLDE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NASDAQ_TXG_2019.pdf</td>\n",
       "      <td>b'%PDF-1.4\\n%\\xd3\\xeb\\xe9\\xe1\\n1 0 obj\\n&lt;&lt;/Cre...</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NASDAQ_TXG</td>\n",
       "      <td>Table of Contents\\n \\n \\nUNITED STATES\\nSECURI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NASDAQ_TXG_2021.pdf</td>\n",
       "      <td>b'%PDF-1.4\\r\\n%\\xd3\\xf4\\xcc\\xe1\\r\\n1 0 obj\\r\\n...</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>NASDAQ_TXG</td>\n",
       "      <td>Table of Contents\\nUNITED STATES\\nSECURITIES A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NASDAQ_YI_2018.pdf</td>\n",
       "      <td>b'%PDF-1.4\\n%\\xe4\\xe3\\xcf\\xd2\\n1 0 obj\\n[/PDF/...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>NASDAQ_YI</td>\n",
       "      <td>Table of Contents\\n \\nUNITED STATES\\nSECURITIE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NASDAQ_YI_2021.pdf</td>\n",
       "      <td>b'%PDF-1.7\\n%\\x81\\x81\\x81\\x81\\n\\n8 0 obj\\n&lt;&lt;\\n...</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>NASDAQ_YI</td>\n",
       "      <td>Table of Contents\\nUNITED STATES\\n\\nSECURITIES...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NASDAQ_PIH_2015.pdf</td>\n",
       "      <td>b'%PDF-1.6\\r%\\xe2\\xe3\\xcf\\xd3\\r\\n505 0 obj\\r&lt;&lt;...</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>NASDAQ_PIH</td>\n",
       "      <td>2015 Annual Report \\nApril 29, 2016 \\n \\nFello...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NASDAQ_PIH_2017.pdf</td>\n",
       "      <td>b'%PDF-1.5\\r\\n%\\xb5\\xb5\\xb5\\xb5\\r\\n1 0 obj\\r\\n...</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>NASDAQ_PIH</td>\n",
       "      <td>\\n \\n \\n \\n \\n \\n \\nApril 20, 2018 \\n \\nDear ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NASDAQ_BCOW_2021.pdf</td>\n",
       "      <td>b'%PDF-1.4\\r\\n%\\xd3\\xf4\\xcc\\xe1\\r\\n1 0 obj\\r\\n...</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>NASDAQ_BCOW</td>\n",
       "      <td>Table of Contents\\n \\n \\nUNITED STATES\\nSECURI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NASDAQ_BCOW_2022.pdf</td>\n",
       "      <td>b'%PDF-1.4\\r\\n%\\xd3\\xf4\\xcc\\xe1\\r\\n1 0 obj\\r\\n...</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>NASDAQ_BCOW</td>\n",
       "      <td>\\n  \\n  \\nUNITED STATES \\nSECURITIES AND EXCH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NASDAQ_SRCE_2019.pdf</td>\n",
       "      <td>b'%PDF-1.6\\r%\\xe2\\xe3\\xcf\\xd3\\r\\n681 0 obj\\r&lt;&lt;...</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NASDAQ_SRCE</td>\n",
       "      <td>2 0 1 9  A N N U A L  R E P O R T\\nYour partne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NASDAQ_SRCE_2022.pdf</td>\n",
       "      <td>b'%PDF-1.6\\r%\\xe2\\xe3\\xcf\\xd3\\r\\n384 0 obj\\r&lt;&lt;...</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>NASDAQ_SRCE</td>\n",
       "      <td>2 0 2 2  A N N U A L  R E P O R T\\nYour partne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NASDAQ_VNET_2015.pdf</td>\n",
       "      <td>b'%PDF-1.4\\n%\\xd3\\xeb\\xe9\\xe1\\n1 0 obj\\n&lt;&lt;/Cre...</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>NASDAQ_VNET</td>\n",
       "      <td>Table of Contents\\n \\n \\nUNITED STATES\\nSECURI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NASDAQ_VNET_2019.pdf</td>\n",
       "      <td>b'%PDF-1.4\\n%\\xd3\\xeb\\xe9\\xe1\\n1 0 obj\\n&lt;&lt;/Cre...</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NASDAQ_VNET</td>\n",
       "      <td>Table of Contents\\n \\nUNITED STATES\\nSECURITIE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NASDAQ_TWOU_2019.pdf</td>\n",
       "      <td>b'%PDF-1.6\\r%\\xe2\\xe3\\xcf\\xd3\\r\\n2951 0 obj\\r&lt;...</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NASDAQ_TWOU</td>\n",
       "      <td>Blended &amp; Connected.\\nHigh Quality.\\nRelevant....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NASDAQ_TWOU_2022.pdf</td>\n",
       "      <td>b'%PDF-1.4\\r%\\xe2\\xe3\\xcf\\xd3\\r\\n10013 0 obj\\r...</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>NASDAQ_TWOU</td>\n",
       "      <td>2U’s 2022 \\nAnnual Report\\nWorld-Class Partner...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NASDAQ_QFIN_2018.pdf</td>\n",
       "      <td>b'%PDF-1.4\\n%\\xe4\\xe3\\xcf\\xd2\\n1 0 obj\\n[/PDF/...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>NASDAQ_QFIN</td>\n",
       "      <td>Table of Contents\\n \\nUNITED STATES\\nSECURITIE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NASDAQ_QFIN_2020.pdf</td>\n",
       "      <td>b'%PDF-1.4\\n%\\xd3\\xeb\\xe9\\xe1\\n1 0 obj\\n&lt;&lt;/Cre...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>NASDAQ_QFIN</td>\n",
       "      <td>Table of Contents\\nUNITED STATES\\nSECURITIES A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NASDAQ_KRKR_2019.pdf</td>\n",
       "      <td>b'%PDF-1.4\\n%\\xd3\\xeb\\xe9\\xe1\\n1 0 obj\\n&lt;&lt;/Cre...</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NASDAQ_KRKR</td>\n",
       "      <td>Table of Contents\\n \\n \\nUNITED STATES\\nSECURI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NASDAQ_KRKR_2022.pdf</td>\n",
       "      <td>b'%PDF-1.7\\n%\\x81\\x81\\x81\\x81\\n\\n8 0 obj\\n&lt;&lt;\\n...</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>NASDAQ_KRKR</td>\n",
       "      <td>Table of Contents\\nUNITED STATES\\nSECURITIES A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name                                            content  \\\n",
       "0   NASDAQ_FLWS_2019.pdf  b'%PDF-1.6\\r%\\xe2\\xe3\\xcf\\xd3\\r\\n1183 0 obj\\r<...   \n",
       "3   NASDAQ_FLWS_2022.pdf  b'%PDF-1.7\\r%\\xe2\\xe3\\xcf\\xd3\\r\\n743 0 obj\\r<<...   \n",
       "4    NASDAQ_TXG_2019.pdf  b'%PDF-1.4\\n%\\xd3\\xeb\\xe9\\xe1\\n1 0 obj\\n<</Cre...   \n",
       "6    NASDAQ_TXG_2021.pdf  b'%PDF-1.4\\r\\n%\\xd3\\xf4\\xcc\\xe1\\r\\n1 0 obj\\r\\n...   \n",
       "7     NASDAQ_YI_2018.pdf  b'%PDF-1.4\\n%\\xe4\\xe3\\xcf\\xd2\\n1 0 obj\\n[/PDF/...   \n",
       "10    NASDAQ_YI_2021.pdf  b'%PDF-1.7\\n%\\x81\\x81\\x81\\x81\\n\\n8 0 obj\\n<<\\n...   \n",
       "11   NASDAQ_PIH_2015.pdf  b'%PDF-1.6\\r%\\xe2\\xe3\\xcf\\xd3\\r\\n505 0 obj\\r<<...   \n",
       "13   NASDAQ_PIH_2017.pdf  b'%PDF-1.5\\r\\n%\\xb5\\xb5\\xb5\\xb5\\r\\n1 0 obj\\r\\n...   \n",
       "14  NASDAQ_BCOW_2021.pdf  b'%PDF-1.4\\r\\n%\\xd3\\xf4\\xcc\\xe1\\r\\n1 0 obj\\r\\n...   \n",
       "15  NASDAQ_BCOW_2022.pdf  b'%PDF-1.4\\r\\n%\\xd3\\xf4\\xcc\\xe1\\r\\n1 0 obj\\r\\n...   \n",
       "16  NASDAQ_SRCE_2019.pdf  b'%PDF-1.6\\r%\\xe2\\xe3\\xcf\\xd3\\r\\n681 0 obj\\r<<...   \n",
       "19  NASDAQ_SRCE_2022.pdf  b'%PDF-1.6\\r%\\xe2\\xe3\\xcf\\xd3\\r\\n384 0 obj\\r<<...   \n",
       "20  NASDAQ_VNET_2015.pdf  b'%PDF-1.4\\n%\\xd3\\xeb\\xe9\\xe1\\n1 0 obj\\n<</Cre...   \n",
       "24  NASDAQ_VNET_2019.pdf  b'%PDF-1.4\\n%\\xd3\\xeb\\xe9\\xe1\\n1 0 obj\\n<</Cre...   \n",
       "25  NASDAQ_TWOU_2019.pdf  b'%PDF-1.6\\r%\\xe2\\xe3\\xcf\\xd3\\r\\n2951 0 obj\\r<...   \n",
       "28  NASDAQ_TWOU_2022.pdf  b'%PDF-1.4\\r%\\xe2\\xe3\\xcf\\xd3\\r\\n10013 0 obj\\r...   \n",
       "29  NASDAQ_QFIN_2018.pdf  b'%PDF-1.4\\n%\\xe4\\xe3\\xcf\\xd2\\n1 0 obj\\n[/PDF/...   \n",
       "31  NASDAQ_QFIN_2020.pdf  b'%PDF-1.4\\n%\\xd3\\xeb\\xe9\\xe1\\n1 0 obj\\n<</Cre...   \n",
       "32  NASDAQ_KRKR_2019.pdf  b'%PDF-1.4\\n%\\xd3\\xeb\\xe9\\xe1\\n1 0 obj\\n<</Cre...   \n",
       "35  NASDAQ_KRKR_2022.pdf  b'%PDF-1.7\\n%\\x81\\x81\\x81\\x81\\n\\n8 0 obj\\n<<\\n...   \n",
       "\n",
       "      year    base_name                                               text  \n",
       "0   2019.0  NASDAQ_FLWS  D R I V I N G  G R O W T H ,  \\nB U I L D I N ...  \n",
       "3   2022.0  NASDAQ_FLWS  1-800-FLOWERS.COM, INC. \\nLETTER TO SHAREHOLDE...  \n",
       "4   2019.0   NASDAQ_TXG  Table of Contents\\n \\n \\nUNITED STATES\\nSECURI...  \n",
       "6   2021.0   NASDAQ_TXG  Table of Contents\\nUNITED STATES\\nSECURITIES A...  \n",
       "7   2018.0    NASDAQ_YI  Table of Contents\\n \\nUNITED STATES\\nSECURITIE...  \n",
       "10  2021.0    NASDAQ_YI  Table of Contents\\nUNITED STATES\\n\\nSECURITIES...  \n",
       "11  2015.0   NASDAQ_PIH  2015 Annual Report \\nApril 29, 2016 \\n \\nFello...  \n",
       "13  2017.0   NASDAQ_PIH   \\n \\n \\n \\n \\n \\n \\nApril 20, 2018 \\n \\nDear ...  \n",
       "14  2021.0  NASDAQ_BCOW  Table of Contents\\n \\n \\nUNITED STATES\\nSECURI...  \n",
       "15  2022.0  NASDAQ_BCOW   \\n  \\n  \\nUNITED STATES \\nSECURITIES AND EXCH...  \n",
       "16  2019.0  NASDAQ_SRCE  2 0 1 9  A N N U A L  R E P O R T\\nYour partne...  \n",
       "19  2022.0  NASDAQ_SRCE  2 0 2 2  A N N U A L  R E P O R T\\nYour partne...  \n",
       "20  2015.0  NASDAQ_VNET  Table of Contents\\n \\n \\nUNITED STATES\\nSECURI...  \n",
       "24  2019.0  NASDAQ_VNET  Table of Contents\\n \\nUNITED STATES\\nSECURITIE...  \n",
       "25  2019.0  NASDAQ_TWOU  Blended & Connected.\\nHigh Quality.\\nRelevant....  \n",
       "28  2022.0  NASDAQ_TWOU  2U’s 2022 \\nAnnual Report\\nWorld-Class Partner...  \n",
       "29  2018.0  NASDAQ_QFIN  Table of Contents\\n \\nUNITED STATES\\nSECURITIE...  \n",
       "31  2020.0  NASDAQ_QFIN  Table of Contents\\nUNITED STATES\\nSECURITIES A...  \n",
       "32  2019.0  NASDAQ_KRKR  Table of Contents\\n \\n \\nUNITED STATES\\nSECURI...  \n",
       "35  2022.0  NASDAQ_KRKR  Table of Contents\\nUNITED STATES\\nSECURITIES A...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_pdfs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Normalize the data\n",
    "\n",
    "**Normalizing text is crucial for preparing data for further analysis, ensuring the text is consistent and easy to process by removing noise and standardizing the format.**\n",
    "\n",
    "- **Text Cleaning (`clean_text`):** Convert text to lowercase, remove unwanted characters such as punctuation, URLs, HTML tags, and digits.\n",
    "- **Expand Contractions (`expand_contractions`):** Replace contractions (e.g., \"can't\" to \"cannot\") using a predefined dictionary of contractions.\n",
    "- **Lemmatize Text (`lemmatize_text`):** Tokenize the text and apply lemmatization to convert words to their base form (e.g., \"running\" to \"run\").\n",
    "- **Remove Stopwords (`remove_stopwords`):** Tokenize the text and remove common stop words that do not contribute to the meaning (e.g., \"and\", \"the\").\n",
    "- **Normalize Corpus (`normalize_corpus`):** Combine text chunks into a single string if needed, apply text cleaning, contraction expansion, lemmatization, and stop word removal in sequence, save the cleaned and processed text to a `.txt` file with a specified prefix, and return the normalized text and the output file name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T22:20:36.324178Z",
     "start_time": "2024-07-24T22:20:34.152956Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/oem/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/oem/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/oem/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from src import text_normalizer\n",
    "\n",
    "# Text cleanup and normalization\n",
    "cleaned_text = text_normalizer.normalize_corpus(filtered_pdfs_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exploratory Data Analysis (EDA)**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Number of Words in the Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T22:20:36.475940Z",
     "start_time": "2024-07-24T22:20:36.325351Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in the vocabulary: 4013\n",
      "Words in the vocabulary: ['american', 'nir2o2c09', '442', 'risk', 'needed', 'forecast', '2012', 'neuhaus', '2769', 'produce']\n"
     ]
    }
   ],
   "source": [
    "# Call the analyze_text function\n",
    "X, num_words, vocab_sample = analyze_text(cleaned_text)\n",
    "\n",
    "print(\"Number of words in the vocabulary:\", num_words)\n",
    "print(\"Words in the vocabulary:\", vocab_sample)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Sentiment of the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T22:20:36.723550Z",
     "start_time": "2024-07-24T22:20:36.477190Z"
    }
   },
   "outputs": [],
   "source": [
    "sentiment = analyze_sentiment(cleaned_text)\n",
    "print(f\"Sentiment of the text: Polarity={sentiment.polarity}, Subjectivity={sentiment.subjectivity}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T22:20:37.636223Z",
     "start_time": "2024-07-24T22:20:36.724530Z"
    }
   },
   "outputs": [],
   "source": [
    "generate_word_cloud(cleaned_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Common Words Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T22:20:38.030739Z",
     "start_time": "2024-07-24T22:20:37.637532Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_common_words(cleaned_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Top 10 Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T22:20:38.410977Z",
     "start_time": "2024-07-24T22:20:38.032571Z"
    }
   },
   "outputs": [],
   "source": [
    "display_ngrams_with_plot_side_by_side(cleaned_text, n=2, top_n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Feature Engineering\n",
    "\n",
    "In this stage, we have split the texts into fragments and vectorized them so that the machine learning models can understand them. We used the `CharacterTextSplitter` class from LangChain to divide the long texts into more manageable fragments, ensuring that each fragment retains enough context.\n",
    "\n",
    "After splitting the texts, we store the fragments in a new column of the DataFrame. Then, we use OpenAI embeddings to convert these text fragments into numerical vectors. Embeddings are numerical representations that capture the semantics and context of the texts.\n",
    "\n",
    "Finally, we store these vectors in a `VectorStore` using FAISS, a library for searching and storing large amounts of vectors. This will allow us to search and retrieve similar text fragments quickly and efficiently.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T22:20:43.450686Z",
     "start_time": "2024-07-24T22:20:38.412364Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from src import text_processing\n",
    "\n",
    "# Create and save the vectorstore\n",
    "text_processing.create_and_save_vectorstore(cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Ragas Evaluation\n",
    "\n",
    "`ragas` is a library designed for evaluating the performance of question-answering (QA) systems. It provides various metrics to measure the quality of answers generated by these systems. The metrics help in assessing aspects such as the relevance of the answer, faithfulness to the context, precision, recall, correctness, and similarity of the answer.\n",
    "\n",
    "When this code is executed:\n",
    "\n",
    "* A dataset will be loaded from a JSON file.\n",
    "* A set of evaluation metrics will be defined to measure different aspects of the QA system's performance.\n",
    "* The dataset will be evaluated using the specified metrics.\n",
    "* The evaluation results will be processed into two DataFrames: one for the global results and one for the results by question.\n",
    "* The processed results will be returned for analysis or visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data.json file was created successfully\n"
     ]
    }
   ],
   "source": [
    "from src import ragas_utils\n",
    "from src import ragas_model\n",
    "\n",
    "# Read information questions.txt\n",
    "data_questions = ragas_utils.process_information()\n",
    "\n",
    "# Process model for add answer and contexts\n",
    "data_ragas = ragas_model.execute(data_questions)\n",
    "\n",
    "# Create data.json\n",
    "ragas_utils.create_ragas_data_file(data_ragas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f2cd1e405674f6d8f63e695bd0c1e4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad9251710c4b4250a2c20dc7d1a8e42a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src import ragas_evaluate\n",
    "\n",
    "#Evaluation\n",
    "global_result, question_result = ragas_evaluate.get_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>context_precision</th>\n",
       "      <td>0.520833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>faithfulness</th>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_relevancy</th>\n",
       "      <td>0.489166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context_recall</th>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_correctness</th>\n",
       "      <td>0.233045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_similarity</th>\n",
       "      <td>0.932178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Result\n",
       "context_precision   0.520833\n",
       "faithfulness        0.500000\n",
       "answer_relevancy    0.489166\n",
       "context_recall      0.500000\n",
       "answer_correctness  0.233045\n",
       "answer_similarity   0.932178"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>answer_correctness</th>\n",
       "      <th>answer_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What were 1-800-Flowers.com, Inc.'s  2019 tot...</td>\n",
       "      <td>1-800-Flowers.com, Inc.'s 2019 total net reven...</td>\n",
       "      <td>[grow business profitably napcosm resource flo...</td>\n",
       "      <td>1-800-Flowers.com, Inc.'s 2019 total net reve...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973652</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.246630</td>\n",
       "      <td>0.986521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What was 1-800-Flowers.com, Inc.'s gross prof...</td>\n",
       "      <td>1-800-Flowers.com, Inc.'s gross profit margin ...</td>\n",
       "      <td>[30 2017 gross profit gross profit ear ended j...</td>\n",
       "      <td>As of July 2019, 1-800-Flowers.com, Inc.'s gr...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.983010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.240415</td>\n",
       "      <td>0.961660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What were 1-800-Flowers.com, Inc.'s net reven...</td>\n",
       "      <td>I don't have information on 1-800-Flowers.com,...</td>\n",
       "      <td>[offering fully digital livestreaming floral c...</td>\n",
       "      <td>In 2021, 1-800-Flowers.com, Inc.'s net revenu...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.221852</td>\n",
       "      <td>0.887409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What was 1-800-Flowers.com, Inc.'s cost of re...</td>\n",
       "      <td>I don't have that specific information about 1...</td>\n",
       "      <td>[ing synergistic operating cost saving fiscal ...</td>\n",
       "      <td>In 2022, 1-800-Flowers.com, Inc.'s cost of re...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.223281</td>\n",
       "      <td>0.893122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0   What were 1-800-Flowers.com, Inc.'s  2019 tot...   \n",
       "1   What was 1-800-Flowers.com, Inc.'s gross prof...   \n",
       "2   What were 1-800-Flowers.com, Inc.'s net reven...   \n",
       "3   What was 1-800-Flowers.com, Inc.'s cost of re...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  1-800-Flowers.com, Inc.'s 2019 total net reven...   \n",
       "1  1-800-Flowers.com, Inc.'s gross profit margin ...   \n",
       "2  I don't have information on 1-800-Flowers.com,...   \n",
       "3  I don't have that specific information about 1...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [grow business profitably napcosm resource flo...   \n",
       "1  [30 2017 gross profit gross profit ear ended j...   \n",
       "2  [offering fully digital livestreaming floral c...   \n",
       "3  [ing synergistic operating cost saving fiscal ...   \n",
       "\n",
       "                                        ground_truth  context_precision  \\\n",
       "0   1-800-Flowers.com, Inc.'s 2019 total net reve...           0.833333   \n",
       "1   As of July 2019, 1-800-Flowers.com, Inc.'s gr...           1.000000   \n",
       "2   In 2021, 1-800-Flowers.com, Inc.'s net revenu...           0.250000   \n",
       "3   In 2022, 1-800-Flowers.com, Inc.'s cost of re...           0.000000   \n",
       "\n",
       "   faithfulness  answer_relevancy  context_recall  answer_correctness  \\\n",
       "0           1.0          0.973652             1.0            0.246630   \n",
       "1           1.0          0.983010             1.0            0.240415   \n",
       "2           0.0          0.000000             0.0            0.221852   \n",
       "3           0.0          0.000000             0.0            0.223281   \n",
       "\n",
       "   answer_similarity  \n",
       "0           0.986521  \n",
       "1           0.961660  \n",
       "2           0.887409  \n",
       "3           0.893122  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
